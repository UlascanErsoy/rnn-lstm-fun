{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size:int,\n",
    "                        hidden_size:int,\n",
    "                        dropout: float = 0.5,\n",
    "                        hidden_layers: int = 1):\n",
    "        \"\"\"Initialize an RNN\n",
    "        for training purposes\n",
    "        \"\"\"\n",
    "        super(RNN,self).__init__()\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        layers = []\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        for _ in range(hidden_layers):\n",
    "            layers.append(nn.Sequential(\n",
    "                nn.Linear(hidden_size * 2, hidden_size),\n",
    "                nn.Tanh(),\n",
    "                nn.Dropout(dropout)\n",
    "            ))\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        self.h2o = nn.Linear(hidden_size, input_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        encoded = self.i2h(input)\n",
    "\n",
    "        for idx, rnn_lay in enumerate(self.layers):\n",
    "            combined = torch.cat((encoded, hidden[idx:idx+1]),1)\n",
    "            encoded  = rnn_lay(combined)\n",
    "            hidden[idx] = encoded\n",
    "\n",
    "        output = self.softmax(self.h2o(encoded))\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.randn(self.hidden_layers, self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = \"\".join([\"a\",\"b\",\"c\",\"ç\",\"d\",\"e\",\"f\",\"g\",\"ğ\",\"h\",\"ı\",\"i\",\n",
    "                \"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"ö\",\"p\",\"q\",\"r\",\"s\",\"ş\",\"t\",\n",
    "                \"u\",\"ü\",\"v\",\"w\",\"x\",\"y\",\"z\",\".\",\";\",\",\",\"?\",\"!\", \" \",\n",
    "                \"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\",\"[\",\"]\",\n",
    "                \"{\",\"}\",\"(\",\")\",\"'\",\"\\\"\",\"%\",\":\",\"\\n\",\"\\r\\n\",\"-\",\"$\",\"+\",\n",
    "                \"*\",\"/\",\"#\",\"@\"])\n",
    "\n",
    "def letter_to_index(letter: str):\n",
    "    \"\"\"converts letter to an index\n",
    "    \"\"\"\n",
    "    return all_letters.find(letter.lower())\n",
    "\n",
    "def letter_to_tensor(letter: str):\n",
    "    tensor = torch.zeros(1, len(all_letters))\n",
    "    tensor[0][letter_to_index(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def line_to_tensor(line):\n",
    "    tensor = torch.zeros(len(line),1,len(all_letters),dtype=torch.float32)\n",
    "    for idx, letter in tqdm(enumerate(line)):\n",
    "        tensor[idx][0][letter_to_index(letter)] = 1\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217 files found!\n",
      "2994149 characters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2993152it [00:13, 214022.30it/s]\n"
     ]
    }
   ],
   "source": [
    "#prep training data\n",
    "\n",
    "def prep_training_data(path):\n",
    "    \"\"\"load data from a path with\n",
    "    txt files\n",
    "    \"\"\"\n",
    "    files = os.listdir(path)\n",
    "    print(f\"{len(files)} files found!\")\n",
    "    texts = \"\".join([open(os.path.join(path, file),\"r\").read()\n",
    "                for file in files]).lower()\n",
    "\n",
    "    print(f\"{len(texts)} characters...\")\n",
    "\n",
    "    texts = \"\".join([ch for ch in texts if ch in all_letters])\n",
    "\n",
    "    return line_to_tensor(texts)\n",
    "    \n",
    "\n",
    "input = prep_training_data(\"./paul_graham/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def train(rnn, inputs, optimizer,lr=0.005):\n",
    "    \n",
    "    \n",
    "    rnn.train()\n",
    "    hidden = rnn.init_hidden()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    losses = 0\n",
    "    clipping_value = 1 # arbitrary value of your choosing\n",
    "    for idx in range(inputs.shape[0]-1):\n",
    "        output, hidden = rnn(inputs[idx], hidden)\n",
    "        loss = loss_fn(torch.flatten(output), torch.flatten(inputs[idx+1]))\n",
    "        losses += loss\n",
    "    \n",
    "    loss.backward()\n",
    "    #optimizer.step()\n",
    "    torch.nn.utils.clip_grad_norm_(rnn.parameters(), clipping_value)\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-lr)\n",
    "\n",
    "    return losses / (inputs.shape[0])\n",
    "\n",
    "print(f\"Device is {device}\")\n",
    "\n",
    "rnn = RNN(\n",
    "    input_size=len(all_letters),\n",
    "    hidden_size=512,\n",
    "    hidden_layers=2\n",
    ").to(device)\n",
    "rnn.load_state_dict(torch.load(\"rnn_512_2layer_softmax_final.bin\"))\n",
    "\n",
    "inputs = input.to(device)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]/home/cake/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "Epoch 2 | Loss: 2.57:   0%|          | 3/10000 [00:00<21:55,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Avg loss: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Loss: 2.96:   0%|          | 33/10000 [00:02<14:35, 11.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m rnn\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m inps \u001b[39m=\u001b[39m inputs[batch\u001b[39m*\u001b[39mbatch_size: batch\u001b[39m*\u001b[39mbatch_size \u001b[39m+\u001b[39m batch_size]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m loss \u001b[39m=\u001b[39m train(rnn, inps, optimizer,lr\u001b[39m=\u001b[39;49m\u001b[39m0.005\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss_epoch\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m pbar\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m | Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m clipping_value \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m# arbitrary value of your choosing\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(inputs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     output, hidden \u001b[39m=\u001b[39m rnn(inputs[idx], hidden)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(torch\u001b[39m.\u001b[39mflatten(output), torch\u001b[39m.\u001b[39mflatten(inputs[idx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     losses \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     combined \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((encoded, hidden[idx:idx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]),\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     encoded  \u001b[39m=\u001b[39m rnn_lay(combined)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     hidden[idx] \u001b[39m=\u001b[39m encoded\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh2o(encoded))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cake/workspace/rnn-lstm-fun/rnn-char.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output, hidden\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "batch_count = inputs.shape[0]//batch_size\n",
    "\n",
    "loss_epoch = []\n",
    "while True:\n",
    "\n",
    "    pbar = tqdm(range(10000))\n",
    "    for epoch in pbar:\n",
    "\n",
    "        batch = int(random.random() * batch_count)\n",
    "        rnn.zero_grad()\n",
    "        inps = inputs[batch*batch_size: batch*batch_size + batch_size]\n",
    "        loss = train(rnn, inps, optimizer,lr=0.005)\n",
    "        loss_epoch.append(loss)\n",
    "        pbar.set_description(f\"Epoch {epoch} | Loss: {loss:.2f}\")\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "                print(f\"Epoch {epoch} Avg loss: {sum(loss_epoch)/len(loss_epoch):.2f}\")\n",
    "                loss_epoch = []\n",
    "\n",
    "    print(f\"Epoch {epoch} Avg loss: {sum(loss_epoch)/len(loss_epoch):.2f}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(rnn.state_dict(), \"rnn.bin\")\n",
    "#rnn.load_state_dict(torch.load(\"rnn_2layer_512_softmax.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ke the and the saing in a just the sime the more the make the read the companay companies and what the was the with companies the and vers was the in the was must of the mant of dang the fire what the nound in a startups whing be compans af you can a vertion of the pare the most in the are in and deally for the something in the startups are was whit startups in a startups are the compant the for and you dange of the same the sale was the sive in the companies when the sime the was in a startups are the sime and the company deally startups and startups was of the most of the ind really the make a kead in a companies of the startups prople the startups are a startups in prowere the sact as the sime the and deally startups in the difers same the compance and startups more some the was in the companies in the mighat is the companies the was a make the best companing the pars was the dide the prople and startups and was of the not was a for the same the mach companies the a for the bere the"
     ]
    }
   ],
   "source": [
    "\n",
    "rnn.eval()\n",
    "\n",
    "def tensor_to_char(tensor):\n",
    "    return all_letters[int((tensor == 1).nonzero(as_tuple=True)[0])]\n",
    "\n",
    "ch = \"\"\n",
    "output = letter_to_tensor(ch).to(device)\n",
    "\n",
    "hidden = rnn.init_hidden()\n",
    "print(ch,end=\"\")\n",
    "with torch.no_grad():\n",
    "    for idx in range(1000):\n",
    "\n",
    "        output, hidden = rnn(output, hidden)\n",
    "        output_dist = output.data.view(-1).div(0.6).exp()\n",
    "        top_i = int(torch.multinomial(output_dist, 1)[0])\n",
    "        #top_i = int(output.argmax())#\n",
    "        print(all_letters[top_i],end=\"\")\n",
    "        output = letter_to_tensor(all_letters[top_i]).to(device)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
